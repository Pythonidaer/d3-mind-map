import { COLORS } from '../../../theme/colors';

export const nodes = [
  {
    id: 'root',
    label: 'Security Best Practices\nfor LLM Applications',
    shape: 'roundRect',
    color: 'root',
    definition: 'Guidelines and strategies to protect LLM systems from prompt injection, data breaches, tool misuse, and operational vulnerabilities.',
  },
  {
    id: 'prompt_injection_defense',
    label: 'Prompt Injection\nDefense',
    shape: 'ellipse',
    color: 'nodePositive1',
    parent: 'root',
    definition: 'Strategies to prevent users or external sources from injecting malicious instructions into LLM prompts or tool flows.',
  },
  {
    id: 'input_validation',
    label: 'Strict Input\nValidation',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'prompt_injection_defense',
    definition: 'Sanitize and validate user inputs to filter out prompt manipulations, commands, or adversarial triggers.',
  },
  {
    id: 'output_guardrails',
    label: 'Output Guardrails\nand Validation',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'prompt_injection_defense',
    definition: 'Post-process LLM outputs to detect unsafe, hallucinated, or manipulated content before exposure to users or systems.',
  },
  {
    id: 'tool_use_restriction',
    label: 'Restricted\nTool Access',
    shape: 'ellipse',
    color: 'nodePositive1',
    parent: 'root',
    definition: 'Security boundaries for AI agents or LLMs interacting with external APIs, memory, or systems.',
  },
  {
    id: 'tool_whitelisting',
    label: 'Tool Whitelisting\nand Authorization',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'tool_use_restriction',
    definition: 'Explicitly limit LLM access only to vetted tools or APIs with strict parameter controls and safe fallbacks.',
  },
  {
    id: 'memory_sanitization',
    label: 'Memory Sanitization\nand Boundaries',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'tool_use_restriction',
    definition: 'Prevent agents from reading/writing sensitive memory locations or retaining unfiltered user data across sessions.',
  },
  {
    id: 'data_protection',
    label: 'Data Protection\nand Privacy',
    shape: 'ellipse',
    color: 'nodePositive1',
    parent: 'root',
    definition: 'Safeguarding sensitive user inputs, outputs, and interaction logs against unauthorized access or misuse.',
  },
  {
    id: 'encryption_and_access_control',
    label: 'Encryption and\nAccess Control',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'data_protection',
    definition: 'Encrypt stored data, secure communications (HTTPS/TLS), and enforce role-based access for data storage and APIs.',
  },
  {
    id: 'anonymization',
    label: 'Data\nAnonymization',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'data_protection',
    definition: 'Strip or mask personally identifiable information (PII) from logs, memory, training data, and prompts.',
  },
  {
    id: 'attack_detection',
    label: 'Attack Detection\nand Response',
    shape: 'ellipse',
    color: 'nodePositive1',
    parent: 'root',
    definition: 'Building systems that monitor for and respond to adversarial attempts targeting LLM applications.',
  },
  {
    id: 'rate_limiting',
    label: 'Rate Limiting\nand Abuse Prevention',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'attack_detection',
    definition: 'Throttle requests by user, IP, or API key to prevent prompt flooding, denial-of-service, or data scraping attacks.',
  },
  {
    id: 'anomaly_detection',
    label: 'Anomaly Detection\non Inputs and Outputs',
    shape: 'rect',
    color: 'nodePositive2',
    parent: 'attack_detection',
    definition: 'Use automated or semi-automated methods to detect unusual patterns in prompts, outputs, or system behavior.',
  },
];

export const links = [
  { source: 'root', target: 'prompt_injection_defense' },
  { source: 'prompt_injection_defense', target: 'input_validation' },
  { source: 'prompt_injection_defense', target: 'output_guardrails' },

  { source: 'root', target: 'tool_use_restriction' },
  { source: 'tool_use_restriction', target: 'tool_whitelisting' },
  { source: 'tool_use_restriction', target: 'memory_sanitization' },

  { source: 'root', target: 'data_protection' },
  { source: 'data_protection', target: 'encryption_and_access_control' },
  { source: 'data_protection', target: 'anonymization' },

  { source: 'root', target: 'attack_detection' },
  { source: 'attack_detection', target: 'rate_limiting' },
  { source: 'attack_detection', target: 'anomaly_detection' },
];
